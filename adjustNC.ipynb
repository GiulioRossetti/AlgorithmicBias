{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nclusters_meanshift(data, bw):\n",
    "    ops = {i: data[i] for i in range(len(data))}\n",
    "    sorted_ops = sorted(ops.items(), key = lambda kv:(kv[1], kv[0]))\n",
    "    A=np.array([el[1] for el in sorted_ops]).reshape(-1,1)\n",
    "    clustering = MeanShift(bandwidth=bw).fit(A)\n",
    "    lbls = clustering.labels_\n",
    "    labels = np.arange(len(sorted_ops))\n",
    "    for i in range(len(labels)):\n",
    "        cl = lbls[i]\n",
    "        labels[sorted_ops[i][0]]=cl\n",
    "    cluster_participation_dict = {}\n",
    "    for l in labels:\n",
    "        if l not in cluster_participation_dict:\n",
    "            cluster_participation_dict[l] = 1\n",
    "        else:\n",
    "            cluster_participation_dict[l] += 1\n",
    "    #computing effective number of clusters using function explained in the paper\n",
    "    C_num = 0\n",
    "    C_den = 0\n",
    "    for k in cluster_participation_dict:\n",
    "        C_num += cluster_participation_dict[k]\n",
    "        C_den += ((cluster_participation_dict[k])**2)\n",
    "    C_num = (C_num**2)\n",
    "    C = C_num/C_den\n",
    "    return C\n",
    "\n",
    "def nclusters(data, threshold):\n",
    "    data = [float(el) for el in data]\n",
    "    data = sorted(data)\n",
    "    start = data[0]\n",
    "    max_val = start + threshold\n",
    "    c = (start, max_val)\n",
    "    cluster = dict()\n",
    "    for i in data:\n",
    "        if i <= max_val:\n",
    "            if c in cluster.keys():\n",
    "                cluster[c] += 1\n",
    "            else:\n",
    "                cluster[c] = 1\n",
    "        else:\n",
    "            max_val = i + threshold\n",
    "            c = (i, max_val)\n",
    "            cluster[c] = 1\n",
    "    #ora ho il dizionario con i cluster di una run\n",
    "    C_num = len(data)**2\n",
    "    C_den = 0\n",
    "    for k in cluster.keys():\n",
    "        C_den += cluster[k]*cluster[k]\n",
    "    C = C_num / C_den\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"aggregate/results.csv\")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_values_avg = []\n",
    "new_values_std = []\n",
    "for index, row in results.iterrows():\n",
    "    media_op = ', '.join(str(el) for el in row['media_op'].split(';'))\n",
    "    mo = f'[{media_op}]'\n",
    "    eps = row['eps']\n",
    "    gam = row['gam']\n",
    "    p_media = row['p_media']\n",
    "    name = f'media mo{mo} p{p_media} e{eps} g{gam} gm{gam} mi1000000'\n",
    "    print(f'doing {name}')\n",
    "    try:\n",
    "        ncarray = []\n",
    "        for nr in data.keys():\n",
    "            csvfile = open(f'res/final_opinions {name} nr{nr}.csv')\n",
    "            finalops = csvfile.readlines()\n",
    "            finalops = finalops.strip().split()\n",
    "            nc = nclusters_meanshift(finalops, bw=0.01)\n",
    "            ncarray.append(nc)\n",
    "        ncarray = np.array(ncarray)\n",
    "        new_values_avg.append(np.average(ncarray))\n",
    "        new_values_std.append(np.std(ncarray))\n",
    "    except FileNotFoundError:\n",
    "        new_values_avg.append(None)\n",
    "        new_values_std.append(None)\n",
    "results[\"0.01MS_avg_ncluster\"] = new_values_avg\n",
    "results[\"0.01MS_std_ncluster\"] = new_values_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_values_avg = []\n",
    "new_values_std = []\n",
    "for index, row in results.iterrows():\n",
    "    media_op = ', '.join(str(el) for el in row['media_op'].split(';'))\n",
    "    mo = f'[{media_op}]'\n",
    "    eps = row['eps']\n",
    "    gam = row['gam']\n",
    "    p_media = row['p_media']\n",
    "    name = f'media mo{mo} p{p_media} e{eps} g{gam} gm{gam} mi1000000'\n",
    "    print(f'doing {name}')\n",
    "    try:\n",
    "        ncarray = []\n",
    "        for nr in data.keys():\n",
    "            csvfile = open(f'res/final_opinions {name} nr{nr}.csv')\n",
    "            finalops = csvfile.readlines()\n",
    "            finalops = finalops.strip().split()\n",
    "            nc = nclusters_meanshift(finalops, bw=0.00001)\n",
    "            ncarray.append(nc)\n",
    "        ncarray = np.array(ncarray)\n",
    "        new_values_avg.append(np.average(ncarray))\n",
    "        new_values_std.append(np.std(ncarray))\n",
    "    except FileNotFoundError:\n",
    "        new_values_avg.append(None)\n",
    "        new_values_std.append(None)     \n",
    "results[\"0.00001MS_avg_ncluster\"] = new_values_avg\n",
    "results[\"0.00001MS_std_ncluster\"] = new_values_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_values_avg = []\n",
    "new_values_std = []\n",
    "for index, row in results.iterrows():\n",
    "    media_op = ', '.join(str(el) for el in row['media_op'].split(';'))\n",
    "    mo = f'[{media_op}]'\n",
    "    eps = row['eps']\n",
    "    gam = row['gam']\n",
    "    p_media = row['p_media']\n",
    "    name = f'media mo{mo} p{p_media} e{eps} g{gam} gm{gam} mi1000000'\n",
    "    print(f'doing {name}')\n",
    "    try:\n",
    "        nitarray = []\n",
    "        for nr in data.keys():\n",
    "            csvfile = f'res/{name} nr{nr}.csv'\n",
    "            with open(csvfile) as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                line_count = 0\n",
    "                for row in csv_reader:\n",
    "                    linecount +=1\n",
    "                nitarray.append(linecount)\n",
    "        nitarray = np.array(nitarray)\n",
    "        new_values_avg.append(np.average(nitarray))\n",
    "        new_values_std.append(np.std(nitarray))\n",
    "    except FileNotFoundError:\n",
    "        new_values_avg.append(None)\n",
    "        new_values_std.append(None)     \n",
    "results[\"avg_niter\"] = new_values_avg\n",
    "results[\"std_niter\"] = new_values_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"aggregate/results2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"aggregate/results2.csv\", index_col=[0])\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_filenames = dict()\n",
    "for filename in os.listdir(\"aggregate/\"):\n",
    "    if filename not in dict_of_filenames:\n",
    "        dict_of_filenames[filename] = 1\n",
    "    else:\n",
    "        dict_of_filenames[filename] += 1\n",
    "dict_of_duplicates = {key: val for key, val in dict_of_filenames.items() if val > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_of_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files renamed\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for filename in os.listdir(\"aggregate/\"):\n",
    "    if filename.startswith(\"averages media\"):\n",
    "        l = filename.split(' ')\n",
    "        if l[2] == 'media':\n",
    "            l.pop(2)\n",
    "            s = ' '.join(l)\n",
    "            try:\n",
    "                os.rename('aggregate/{}'.format(filename), 'aggregate/{}'.format(s))\n",
    "                c +=1\n",
    "            except:\n",
    "                continue\n",
    "print(\"{} files renamed\".format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminati 0 file\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for filename in os.listdir(\"aggregate/\"):\n",
    "    if filename.endswith(\"stofacendoleprove.json\"):\n",
    "        os.remove(\"aggregate/{}\".format(filename))\n",
    "        c+=1\n",
    "print(\"eliminati {} file\".format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create one aggregate file\n",
    "aggrfile = open(\"aggregate/aggregate_results.csv\", \"w+\")\n",
    "header = \"n,density,eps,gam,gam_media,p_media,max_it,media_op,avg_ncluster,std_ncluster,avg_pwdist,std_pwdist,avg_niter,std_niter\\n\"\n",
    "aggrfile.write(header)\n",
    "aggrfile.close()\n",
    "aggrfile = open(\"aggregate/aggregate_results.csv\", \"a+\")\n",
    "for filename in os.listdir(\"aggregate/\"):\n",
    "    if filename.startswith(\"averages media\"):\n",
    "        infile = open(\"aggregate/{}\".format(filename), \"r\")\n",
    "        line = infile.readlines()\n",
    "        s=','.join(line)\n",
    "        s+='\\n'\n",
    "        aggrfile.write(s)\n",
    "        infile.close()\n",
    "aggrfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532\n"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(\"aggregate/aggregate_results.csv\")\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"aggregate/aggregate_results.csv\")\n",
    "metrics = pd.read_csv(\"metrics/metrics [0.0].csv\")\n",
    "entropy = pd.read_csv(\"aggregate/aggregate_entropy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n"
     ]
    }
   ],
   "source": [
    "results[\"media_op\"].replace({\"[0.0]\": \"0.0\"}, inplace=True)\n",
    "results[\"media_op\"].replace({\"[0.0]\": \"0.0\"}, inplace=True)\n",
    "results.drop_duplicates(subset = ['eps', 'gam', 'p_media', 'media_op'], inplace=True)\n",
    "results.to_csv(\"aggregate/aggregate_results.csv\")\n",
    "results = pd.read_csv(\"aggregate/aggregate_results.csv\")\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
